{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Define ResNet18 model.\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Add, GlobalAvgPool2D, Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "cifar100 = tf.keras.datasets.cifar100 \n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
    "\n",
    "class BasicBlock_withResidule(Layer):\n",
    "    def __init__(self, filters: int, strides: int, downsample=False):\n",
    "        super().__init__()\n",
    "        self.conv0 = Conv2D(filters, kernel_size=3, padding=\"same\", strides=strides)\n",
    "        self.bn0 = BatchNormalization()\n",
    "        self.relu0 = ReLU()\n",
    "\n",
    "        self.conv1 = Conv2D(filters, kernel_size=3, padding=\"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.add = Add()\n",
    "        self.relu1 = ReLU()\n",
    "        if downsample and strides != 1:\n",
    "          # self.downsample = Conv2D(filters, kernel_size=1, strides=strides)\n",
    "          self.downsample = Sequential([Conv2D(filters, kernel_size=1, strides=strides),\n",
    "                                        BatchNormalization()])\n",
    "\n",
    "        else:\n",
    "          self.downsample = Layer() # identity layer\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        x = self.conv0(inputs)\n",
    "        x = self.bn0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        identity = self.downsample(inputs)\n",
    "        output = self.add([identity, x])\n",
    "\n",
    "        output = self.relu1(output)\n",
    "        return output\n",
    "\n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self, num_classess=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(64, 7, strides=2, padding=\"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPooling2D(3, strides=2, padding=\"same\")\n",
    "\n",
    "        num_block = 2\n",
    "\n",
    "        # Longer version of code\n",
    "        conv2_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv2_x_block.append(BasicBlock_withResidule(filters=64, strides=1, downsample=False))\n",
    "        self.conv2_x = Sequential(conv2_x_block)\n",
    "\n",
    "        conv3_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv3_x_block.append(BasicBlock_withResidule(filters=128, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False))\n",
    "        self.conv3_x = Sequential(conv3_x_block)\n",
    "\n",
    "        conv4_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv4_x_block.append(BasicBlock_withResidule(filters=256, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False))\n",
    "        self.conv4_x = Sequential(conv4_x_block)\n",
    "\n",
    "        conv5_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv5_x_block.append(BasicBlock_withResidule(filters=512, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False))\n",
    "        self.conv5_x = Sequential(conv5_x_block)\n",
    "\n",
    "        # Shorter version of code\n",
    "        # self.conv2_x = Sequential([BasicBlock_withResidule(filters=64, strides=1, downsample=False)])\n",
    "        # self.conv3_x = Sequential([BasicBlock_withResidule(filters=128, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False) for idx_b in range(num_block)])\n",
    "        # self.conv4_x = Sequential([BasicBlock_withResidule(filters=256, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False) for idx_b in range(num_block)])\n",
    "        # self.conv5_x = Sequential([BasicBlock_withResidule(filters=512, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False) for idx_b in range(num_block)])\n",
    "\n",
    "\n",
    "        self.global_pool = GlobalAvgPool2D()\n",
    "        self.fc = Dense(5)\n",
    "\n",
    "        self.build(input_shape=(None, 224, 224, 3))\n",
    "        self.call(Input(shape=(224, 224, 3)))\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Compile the model with optimizer, loss and metrics\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Keras offers plenty of callbacks function\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "epochs = 50\n",
    "resnet_18 = ResNet18()\n",
    "resnet_18.compile(optimizer=\"adam\",\n",
    "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "# reduce learning rate when the loss is not decreasing after 3 continuous epochs\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor=\"loss\", factor=0.5, patience=3, verbose=2, min_lr=1e-8\n",
    ")\n",
    "history = resnet_18.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[reduce_lr_callback])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
