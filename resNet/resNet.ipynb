{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Define ResNet18 model.\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Add, GlobalAvgPool2D, Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "cifar100 = tf.keras.datasets.cifar100 \n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock_withResidule(Layer):\n",
    "    def __init__(self, filters: int, strides: int, downsample=False):\n",
    "        super().__init__()\n",
    "        self.conv0 = Conv2D(filters, kernel_size=3, padding=\"same\", strides=strides)\n",
    "        self.bn0 = BatchNormalization()\n",
    "        self.relu0 = ReLU()\n",
    "\n",
    "        self.conv1 = Conv2D(filters, kernel_size=3, padding=\"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.add = Add()\n",
    "        self.relu1 = ReLU()\n",
    "        if downsample and strides != 1:\n",
    "          # self.downsample = Conv2D(filters, kernel_size=1, strides=strides)\n",
    "          self.downsample = Sequential([Conv2D(filters, kernel_size=1, strides=strides),\n",
    "                                        BatchNormalization()])\n",
    "\n",
    "        else:\n",
    "          self.downsample = Layer() # identity layer\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        x = self.conv0(inputs)\n",
    "        x = self.bn0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        identity = self.downsample(inputs)\n",
    "        output = self.add([identity, x])\n",
    "\n",
    "        output = self.relu1(output)\n",
    "        return output\n",
    "\n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self, num_classess=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(64, 7, strides=2, padding=\"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPooling2D(3, strides=2, padding=\"same\")\n",
    "\n",
    "        num_block = 2\n",
    "\n",
    "        # Longer version of code\n",
    "        conv2_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv2_x_block.append(BasicBlock_withResidule(filters=64, strides=1, downsample=False))\n",
    "        self.conv2_x = Sequential(conv2_x_block)\n",
    "\n",
    "        conv3_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv3_x_block.append(BasicBlock_withResidule(filters=128, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False))\n",
    "        self.conv3_x = Sequential(conv3_x_block)\n",
    "\n",
    "        conv4_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv4_x_block.append(BasicBlock_withResidule(filters=256, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False))\n",
    "        self.conv4_x = Sequential(conv4_x_block)\n",
    "\n",
    "        conv5_x_block = []\n",
    "        for idx_b in range(num_block):\n",
    "          conv5_x_block.append(BasicBlock_withResidule(filters=512, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False))\n",
    "        self.conv5_x = Sequential(conv5_x_block)\n",
    "\n",
    "        # Shorter version of code\n",
    "        # self.conv2_x = Sequential([BasicBlock_withResidule(filters=64, strides=1, downsample=False)])\n",
    "        # self.conv3_x = Sequential([BasicBlock_withResidule(filters=128, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False) for idx_b in range(num_block)])\n",
    "        # self.conv4_x = Sequential([BasicBlock_withResidule(filters=256, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False) for idx_b in range(num_block)])\n",
    "        # self.conv5_x = Sequential([BasicBlock_withResidule(filters=512, strides=2 if idx_b == 0 else 1, downsample=True if idx_b == 0 else False) for idx_b in range(num_block)])\n",
    "\n",
    "\n",
    "        self.global_pool = GlobalAvgPool2D()\n",
    "        self.fc = Dense(5)\n",
    "\n",
    "        self.build(input_shape=(None, 224, 224, 3))\n",
    "        self.call(Input(shape=(224, 224, 3)))\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jon/Documents/CNN_projects/tenserflow_env/lib/python3.11/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'res_net18_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/Users/jon/Documents/CNN_projects/tenserflow_env/lib/python3.11/site-packages/keras/src/layers/layer.py:1295: UserWarning: Layer 'basic_block_with_residule_8' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Exception encountered when calling Layer.call().\n",
      "\n",
      "\u001b[1mLayer Layer does not have a `call()` method implemented.\u001b[0m\n",
      "\n",
      "Arguments received by Layer.call():\n",
      "  • args=('tf.Tensor(shape=(None, 56, 56, 64), dtype=float32)',)\n",
      "  • kwargs=<class 'inspect._empty'>''\n",
      "  warnings.warn(\n",
      "/Users/jon/Documents/CNN_projects/tenserflow_env/lib/python3.11/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'basic_block_with_residule_8', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception encountered when calling BasicBlock_withResidule.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'basic_block_with_residule_8' (of type BasicBlock_withResidule). Either the `BasicBlock_withResidule.call()` method is incorrect, or you need to implement the `BasicBlock_withResidule.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling Layer.call().\n\n\u001b[1mLayer Layer does not have a `call()` method implemented.\u001b[0m\n\nArguments received by Layer.call():\n  • args=('tf.Tensor(shape=(None, 56, 56, 64), dtype=float32)',)\n  • kwargs=<class 'inspect._empty'>\u001b[0m\n\nArguments received by BasicBlock_withResidule.call():\n  • args=('<KerasTensor shape=(None, 56, 56, 64), dtype=float32, sparse=None, name=keras_tensor_11>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseCategoricalCrossentropy\n\u001b[1;32m      7\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 8\u001b[0m resnet_18 \u001b[38;5;241m=\u001b[39m \u001b[43mResNet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m resnet_18\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                   loss\u001b[38;5;241m=\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     11\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m history \u001b[38;5;241m=\u001b[39m resnet_18\u001b[38;5;241m.\u001b[39mfit((train_images, train_labels), validation_data\u001b[38;5;241m=\u001b[39m(test_images, test_labels), epochs\u001b[38;5;241m=\u001b[39mepochs)\n",
      "Cell \u001b[0;32mIn[3], line 94\u001b[0m, in \u001b[0;36mResNet18.__init__\u001b[0;34m(self, num_classess)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 102\u001b[0m, in \u001b[0;36mResNet18.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m     99\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(x)\n\u001b[1;32m    100\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[0;32m--> 102\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3_x(x)\n\u001b[1;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4_x(x)\n",
      "File \u001b[0;32m~/Documents/CNN_projects/tenserflow_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m, in \u001b[0;36mBasicBlock_withResidule.call\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m---> 45\u001b[0m identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd([identity, x])\n\u001b[1;32m     48\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(output)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception encountered when calling BasicBlock_withResidule.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'basic_block_with_residule_8' (of type BasicBlock_withResidule). Either the `BasicBlock_withResidule.call()` method is incorrect, or you need to implement the `BasicBlock_withResidule.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling Layer.call().\n\n\u001b[1mLayer Layer does not have a `call()` method implemented.\u001b[0m\n\nArguments received by Layer.call():\n  • args=('tf.Tensor(shape=(None, 56, 56, 64), dtype=float32)',)\n  • kwargs=<class 'inspect._empty'>\u001b[0m\n\nArguments received by BasicBlock_withResidule.call():\n  • args=('<KerasTensor shape=(None, 56, 56, 64), dtype=float32, sparse=None, name=keras_tensor_11>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "# TODO - Compile the model with optimizer, loss and metrics\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "resnet_18 = ResNet18()\n",
    "resnet_18.compile(optimizer=\"adam\",\n",
    "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "history = resnet_18.fit((train_images, train_labels), validation_data=(test_images, test_labels), epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenserflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
