{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, UpSampling2D\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def conv_block(input, filters):\n",
    "\n",
    "    skip = Conv2D(filters, 1, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(input)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Add()([x, skip])\n",
    "    x = Dropout(0.2)(x)\n",
    "    return x\n",
    "\n",
    "def decoder_block(x, skip, filters):\n",
    "    x = Conv2DTranspose(filters, (3, 3), strides=2, padding=\"same\")(x)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def feature_pyramid(feature_maps):\n",
    "    d1,d2,d3,d4,d5 = feature_maps\n",
    "\n",
    "    p1 = conv_block(d1, 42)\n",
    "    p2 = Add()([UpSampling2D(size=(2, 2))(p1), Conv2D(42, 1, padding=\"same\")(d2)])\n",
    "    p3 = Add()([UpSampling2D(size=(2, 2))(p2), Conv2D(42, 1, padding=\"same\")(d3)])\n",
    "    p4 = Add()([UpSampling2D(size=(2, 2))(p3), Conv2D(42, 1, padding=\"same\")(d4)])\n",
    "    p5 = Add()([UpSampling2D(size=(2, 2))(p4), Conv2D(42, 1, padding=\"same\")(d5)])\n",
    "\n",
    "    return p5\n",
    "\n",
    "def build_fcn_with_fpn(output_channels: int):\n",
    "    # Load EfficientNetB0 model as backbone\n",
    "    backbone = effnet\n",
    "    layer1 = backbone.get_layer('input_1').output #224 3\n",
    "    layer1 = conv_block(layer1, 64) #double number of channels\n",
    "    layer1 = Dropout(0.2)(layer1)  # Adding dropout with a rate of 0.2 as specified in the paper\n",
    "\n",
    "    layer3 = backbone.get_layer('block1a_activation').output #112 96\n",
    "    layer4 = backbone.get_layer('block2a_activation').output #56 144\n",
    "    layer5 = backbone.get_layer('block3a_activation').output #14x14x240\n",
    "    layer6 = backbone.get_layer('block4a_activation').output\n",
    "    layer7 = backbone.get_layer('top_activation').output\n",
    "\n",
    "    #upsampling decoder\n",
    "    d1 = decoder_block(layer7, layer6, 288) #\n",
    "    d2 = decoder_block(d1, layer5, 144) #\n",
    "    d3 = decoder_block(d2, layer4, 72) #\n",
    "    d4 = decoder_block(d3, layer3, 52) #\n",
    "    d5 = decoder_block(d4, layer1, 32) #\n",
    "    #21 classes\n",
    "    outputs = feature_pyramid([d1,d2,d3,d4,d5])\n",
    "    outputs = Conv2D(21, 1, padding=\"same\", activation=\"softmax\")(outputs) #use softmax for multiclass detection instead of binary\n",
    "    # Construct the FCN model with FPN\n",
    "    model = Model(inputs=backbone.inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "fcn_fpn_model = build_fcn_with_fpn(output_channels=21)\n",
    "\n",
    "# Print model summary\n",
    "fcn_fpn_model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
